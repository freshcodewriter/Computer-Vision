{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape_cap1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54a99afb769d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mlk_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinSize\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxLevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_EPS\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_COUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_cap1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprev_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprev_weighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape_cap1' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from helper import Blend_faces\n",
    "\n",
    "# Define detector, predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Read replacement video\n",
    "cap2 = cv2.VideoCapture('Dataset/Myvideo/caci.mp4')\n",
    "if (cap2.isOpened() == False): \n",
    "    print(\"Please import replacement video\")\n",
    "ret2, image2 = cap2.read()\n",
    "gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "rects_cap2 = detector(gray2, 1)\n",
    "for (i, rect) in enumerate(rects_cap2):\n",
    "    shape_cap2 = predictor(gray2, rect)\n",
    "    shape_cap2 = face_utils.shape_to_np(shape_cap2)\n",
    "\n",
    "# Read source video\n",
    "cap1 = cv2.VideoCapture('Dataset/Medium/LucianoRosso3.mp4')\n",
    "if (cap1.isOpened() == False): \n",
    "    print(\"Please import source video\")\n",
    "    \n",
    "ret1, image1 = cap1.read()\n",
    "gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "rects_cap1 = detector(gray1, 1)\n",
    "for (i, rect) in enumerate(rects_cap1):\n",
    "    shape_cap1 = predictor(gray1, rect)\n",
    "    shape_cap1 = face_utils.shape_to_np(shape_cap1)\n",
    "    # Detect one face at a time \n",
    "    if(i == 1):\n",
    "        break\n",
    "        \n",
    "# Define output video\n",
    "cap1_width = int(cap1.get(3))\n",
    "cap1_height = int(cap1.get(4))\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 15, (cap1_width,cap1_height))\n",
    "\n",
    "# Optical flow\n",
    "lk_params = dict(winSize  = (15,15),maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "landmarks = shape_cap1.reshape([68,1, 2])\n",
    "prev_point = landmarks.astype(np.float32)\n",
    "prev_weighted = prev_point\n",
    "\n",
    "# Use facial landmarks as feature points to perform optical flow\n",
    "while(1):\n",
    "    new_weighted = np.zeros([68,1,2])\n",
    "    ret, image = cap1.read()\n",
    "    flag = 0\n",
    "    \n",
    "    if ret == 1:\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        prev_point = prev_point.astype(np.float32)\n",
    "        \n",
    "        # compute the new point\n",
    "        new_point, st, err = cv2.calcOpticalFlowPyrLK(gray1, image_gray, prev_point, None, **lk_params)\n",
    "        rects_new = detector(image_gray, 1)\n",
    "        for (i, rect) in enumerate(rects_new):\n",
    "            new_shape = predictor(image_gray, rect)\n",
    "            new_shape = face_utils.shape_to_np(new_shape)\n",
    "            if (i == 1):\n",
    "                break\n",
    "            \n",
    "        landmarks_new = new_shape.reshape(68, 1, 2)\n",
    "        \n",
    "        if new_shape.shape[0] == 68:\n",
    "            flag = 1\n",
    "        \n",
    "        #for each point, compute a runnin average with higher weight on KLT\n",
    "        for point in range(68):\n",
    "            if (flag == 1 and st[point] == 1):\n",
    "                new_weighted[point, :, :] = 0.2*landmarks_new[point, :, :] + 0.8*new_point[point, :, :]\n",
    "            elif (flag == 1 and st[point] == 0):\n",
    "                new_weighted[point, :, :] = 0.8*prev_weighted[point, :, :] + 0.2*landmarks_new[point, :, :]\n",
    "            elif (flag == 0 and st[pt_num] == 1):\n",
    "                new_weighted[point, :, :] = 0.2*prev_weighted[point, :, :] + 0.8*new_point[point, :, :]\n",
    "            else:\n",
    "                new_weighted[point, :, :] = prev_weighted[point, :, :]\n",
    "                \n",
    "        new_weighted = new_weighted.reshape([68,2]).astype(int)\n",
    "        new_weighted_copy = np.copy(new_weighted)\n",
    "        shape_cap2_copy = np.copy(shape_cap2)\n",
    "        image_copy = np.copy(image)\n",
    "        image2_copy = np.copy(image2)\n",
    "        \n",
    "        # blend faces\n",
    "        faces = Blend_faces(new_weighted_copy, shape_cap2_copy, image_copy, image2_copy)             \n",
    "\n",
    "        out.write(faces)\n",
    "        \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # Now update the previous frame and previous points\n",
    "        gray1 = image_gray.copy()\n",
    "        prev_point = new_weighted.reshape(-1,1,2)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap1.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
